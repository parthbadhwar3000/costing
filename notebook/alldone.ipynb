{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length(in mm)</th>\n",
       "      <th>Width (in mm)</th>\n",
       "      <th>Sheet Cost(in Rs.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>610</td>\n",
       "      <td>460</td>\n",
       "      <td>7890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1050</td>\n",
       "      <td>300</td>\n",
       "      <td>2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>914</td>\n",
       "      <td>560</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1050</td>\n",
       "      <td>610</td>\n",
       "      <td>11500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length(in mm)  Width (in mm)  Sheet Cost(in Rs.)\n",
       "0            600            600                1750\n",
       "1            610            460                7890\n",
       "2           1050            300                2350\n",
       "3            914            560               10500\n",
       "4           1050            610               11500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,root_mean_squared_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5193.5791\n",
      "- Mean Absolute Error: 4331.1162\n",
      "- R2 Score: 0.7958\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5891.9425\n",
      "- Mean Absolute Error: 4303.4673\n",
      "- R2 Score: 0.5952\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5193.5792\n",
      "- Mean Absolute Error: 4331.1387\n",
      "- R2 Score: 0.7958\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5892.2596\n",
      "- Mean Absolute Error: 4303.7611\n",
      "- R2 Score: 0.5951\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5195.7228\n",
      "- Mean Absolute Error: 4321.2632\n",
      "- R2 Score: 0.7957\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5880.8586\n",
      "- Mean Absolute Error: 4315.0195\n",
      "- R2 Score: 0.5967\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 4657.7450\n",
      "- Mean Absolute Error: 2992.0074\n",
      "- R2 Score: 0.8358\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 6208.6108\n",
      "- Mean Absolute Error: 4116.5111\n",
      "- R2 Score: 0.5505\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 273.7987\n",
      "- Mean Absolute Error: 88.7037\n",
      "- R2 Score: 0.9994\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 2721.6366\n",
      "- Mean Absolute Error: 1608.3333\n",
      "- R2 Score: 0.9136\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2099.7193\n",
      "- Mean Absolute Error: 1286.1338\n",
      "- R2 Score: 0.9666\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 4260.1264\n",
      "- Mean Absolute Error: 3022.6150\n",
      "- R2 Score: 0.7884\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBRegressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 273.7991\n",
      "- Mean Absolute Error: 88.9972\n",
      "- R2 Score: 0.9994\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 3278.9580\n",
      "- Mean Absolute Error: 2188.3988\n",
      "- R2 Score: 0.8746\n",
      "===================================\n",
      "\n",
      "\n",
      "GradientBoost\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 707.3758\n",
      "- Mean Absolute Error: 506.7639\n",
      "- R2 Score: 0.9962\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 3414.1591\n",
      "- Mean Absolute Error: 2446.2842\n",
      "- R2 Score: 0.8641\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2896.2924\n",
      "- Mean Absolute Error: 2422.1034\n",
      "- R2 Score: 0.9365\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 3628.8302\n",
      "- Mean Absolute Error: 3264.6170\n",
      "- R2 Score: 0.8464\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"GradientBoost\": GradientBoostingRegressor(),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.913619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.874619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>0.864066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost Regressor</td>\n",
       "      <td>0.846435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.788356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.596688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.595166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.595122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Neighbors Regressor</td>\n",
       "      <td>0.550480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model Name  R2_score\n",
       "4            Decision Tree  0.913619\n",
       "6             XGBRegressor  0.874619\n",
       "7            GradientBoost  0.864066\n",
       "8       AdaBoost Regressor  0.846435\n",
       "5  Random Forest Regressor  0.788356\n",
       "2                    Ridge  0.596688\n",
       "0        Linear Regression  0.595166\n",
       "1                    Lasso  0.595122\n",
       "3    K-Neighbors Regressor  0.550480"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list,r2_list)),columns=['Model Name','R2_score']).sort_values(by=\"R2_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params={\n",
    "    \"max_depth\":[None,5,10,15,20],\n",
    "    \"max_features\":[1,5,8,16],\n",
    "    \"min_samples_split\":[1,2,4,8,16],\n",
    "    \"n_estimators\":[100,200,500,1000]\n",
    "}\n",
    "\n",
    "ada_params={\n",
    "    \"n_estimators\":[100,150,200,500],\n",
    "    \"loss\":['linear', 'square', 'exponential'],\n",
    "    \"learning_rate\":[0.1,0.01,0.001]\n",
    "}\n",
    "\n",
    "grad_params={\n",
    "    \"n_estimators\":[100,150,200,500],\n",
    "    \"loss\": ['squared_error','absolute_error', 'huber', 'quantile'],\n",
    "    \"learning_rate\":[0,1,0.01],\n",
    "    \"min_samples_split\":[1,2,4,8,16,32],\n",
    "    \"min_samples_leaf\":[1,2,10,20]\n",
    "}\n",
    "\n",
    "xg_params={\n",
    "    \"learning_rate\":[0.1,0.01],\n",
    "    \"max_depth\":[5,8,12,20,30],\n",
    "    \"n_estimators\":[100,200,300],\n",
    "    \"colsample_bytree\":[0.5,0.8,1,0.3,0.4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv_models=[\n",
    "                    (\"RF\",RandomForestRegressor(),rf_params),\n",
    "                    (\"Adaboost\",AdaBoostRegressor(),ada_params),\n",
    "                    (\"Gradboost\",GradientBoostingRegressor(),grad_params),\n",
    "                    (\"XGboost\",XGBRegressor(),xg_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=5, max_features=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=2, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=2, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=4, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=16, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=16, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=16, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=16, n_estimators=1000; total time=   0.6s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=4, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=4, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=8, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=1, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=8, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=16, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=16, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=16, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=16, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=16, min_samples_split=2, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.6s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=16, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=16, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=16, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=16, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=16, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=1, min_samples_split=16, n_estimators=1000; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.5s\n",
      "[CV] END max_depth=20, max_features=5, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=1, min_samples_split=8, n_estimators=500; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=1000; total time=   0.3s\n",
      "[CV] END max_depth=5, max_features=1, min_samples_split=2, n_estimators=1000; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=500; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=500; total time=   0.1s[CV] END ...learning_rate=0.1, loss=square, n_estimators=100; total time=   0.1s\n",
      "\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "66 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "66 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.71927627        nan 0.71110156 0.71969966 0.71697729        nan\n",
      " 0.6993511  0.71916943        nan 0.7283925  0.67040547 0.67639608\n",
      "        nan 0.72518285 0.70894549 0.6792665  0.71368231 0.7342073\n",
      " 0.69687645 0.73036833 0.7224677  0.72666084        nan 0.70565413\n",
      " 0.7370999  0.6781678  0.68254577 0.7167792         nan        nan\n",
      " 0.71442563 0.71033344        nan 0.72266702 0.673494          nan\n",
      " 0.70930648 0.72058937        nan 0.7095185         nan 0.73328757\n",
      " 0.72986505 0.73545283 0.72334105 0.71569424        nan 0.71425503\n",
      " 0.71278193        nan 0.67902987        nan 0.667783   0.71829458\n",
      " 0.70245695        nan 0.73546198 0.71192524        nan 0.70661269\n",
      " 0.73400048 0.71069183 0.67236332 0.7182164         nan 0.6956234\n",
      " 0.69926116 0.71082865 0.70589069 0.71877851 0.68120217 0.68042843\n",
      " 0.66269327 0.7260515  0.71264506 0.72809108        nan 0.68684627\n",
      " 0.6784039  0.67966776 0.68390629 0.7392317  0.67993566 0.72897058\n",
      " 0.68371125 0.71919917        nan 0.72574723 0.73438966        nan\n",
      " 0.6851717  0.71936784 0.71492909 0.73805222 0.71213015        nan\n",
      " 0.67246965 0.73456392        nan 0.68427902]\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:320: UserWarning: The total space of parameters 36 is smaller than n_iter=100. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=linear, n_estimators=500; total time=   0.3s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=200; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=500; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, loss=square, n_estimators=500; total time=   0.4s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.1, loss=exponential, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=100; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=500; total time=   0.3s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=100; total time=   0.0s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=linear, n_estimators=500; total time=   0.3s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=500; total time=   0.3s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=100; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=200; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=100; total time=   0.0s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=500; total time=   0.3s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=500; total time=   0.3s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=200; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=500; total time=   0.3s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=150; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=linear, n_estimators=500; total time=   0.3s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, loss=square, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=500; total time=   0.2s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=500; total time=   0.3s\n",
      "[CV] END .learning_rate=0.001, loss=square, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0.001, loss=exponential, n_estimators=500; total time=   0.2s\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=1, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=1, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=1, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=8, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=8, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=8, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=10, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=20, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=10, min_samples_split=16, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=20, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=10, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=1, min_samples_split=32, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=1, min_samples_split=32, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=20, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=16, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=1, min_samples_split=32, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=20, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=20, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=16, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=16, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=20, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=10, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=10, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=10, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=16, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=4, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=16, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=10, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=2, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=16, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=10, min_samples_split=16, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=10, min_samples_split=16, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=10, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=20, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=16, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=1, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=2, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=2, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=20, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=1, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=10, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=1, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=10, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=20, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=1, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=1, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=1, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=20, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=20, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=20, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=20, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=10, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=10, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=10, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=10, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=500; total time=   0.4s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=2, min_samples_split=8, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=10, min_samples_split=2, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=1, min_samples_split=16, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=2, min_samples_split=8, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=1, min_samples_split=16, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=2, min_samples_split=8, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=1, min_samples_split=16, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=20, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=2, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=20, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=10, min_samples_split=1, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=10, min_samples_split=32, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=2, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=10, min_samples_split=32, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=2, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=2, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=32, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=500; total time=   0.4s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=10, min_samples_split=32, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=10, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=32, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=10, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=20, min_samples_split=16, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=2, min_samples_split=32, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=32, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=2, min_samples_split=32, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=2, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.3s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=1, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=quantile, min_samples_leaf=20, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=1, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=1, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=1, min_samples_split=1, n_estimators=500; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=squared_error, min_samples_leaf=10, min_samples_split=16, n_estimators=200; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=16, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=20, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=8, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=8, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=20, min_samples_split=32, n_estimators=500; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=8, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=2, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=1, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=quantile, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=0, loss=squared_error, min_samples_leaf=1, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=10, min_samples_split=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=2, min_samples_split=32, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=absolute_error, min_samples_leaf=2, min_samples_split=32, n_estimators=150; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=2, min_samples_split=32, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=quantile, min_samples_leaf=10, min_samples_split=32, n_estimators=200; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=1, loss=huber, min_samples_leaf=2, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=squared_error, min_samples_leaf=2, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END learning_rate=0, loss=huber, min_samples_leaf=20, min_samples_split=4, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0, loss=absolute_error, min_samples_leaf=20, min_samples_split=4, n_estimators=150; total time=   0.0s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "[CV] END learning_rate=0.01, loss=absolute_error, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   0.2s\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "57 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "57 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of GradientBoostingRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [-1.14466617 -0.07601948 -0.07601948         nan  0.56633326 -0.03762109\n",
      " -0.04478706 -1.14466617  0.20515364 -0.03762109         nan  0.58088707\n",
      "         nan -0.07601948 -0.04235667 -2.29851378 -0.07601948  0.67179219\n",
      " -0.97416665  0.22381517 -0.03762109 -0.07601948  0.33391403 -0.03762109\n",
      " -0.04478706  0.32818865         nan -0.07601948 -0.2274828  -0.03762109\n",
      "  0.54361483 -2.29851378 -0.07601948  0.54866615  0.22799961         nan\n",
      " -0.07601948         nan -2.3074881          nan         nan -2.29851378\n",
      "  0.46508995 -0.03762109 -1.14466617         nan -0.07601948         nan\n",
      "  0.57305558         nan         nan         nan -0.03762109  0.19913685\n",
      " -0.08465409  0.2154402   0.30952211  0.14399961  0.19913685 -0.75367544\n",
      "         nan         nan -0.07601948  0.52046099  0.34761866 -0.07601948\n",
      "  0.32155983 -0.03762109  0.46776929 -1.14466617         nan         nan\n",
      "  0.29458822 -0.07601948  0.29458822 -1.83443198  0.53522763  0.13650771\n",
      "         nan  0.34747049  0.16915481 -0.07601948  0.20715328  0.4603848\n",
      " -0.07601948 -0.07601948         nan -0.03762109  0.04153971  0.46297858\n",
      " -0.15732082 -0.03762109 -0.34472293  0.38621448  0.36135527 -0.03762109\n",
      " -0.39229918  0.53994934  0.54794448  0.48681784]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=20, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=12, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=12, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=30, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=30, n_estimators=300; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.0s\n",
      "-------Best params for RF----------\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'max_features': 1, 'max_depth': 15}\n",
      "-------Best params for Adaboost----------\n",
      "{'n_estimators': 200, 'loss': 'square', 'learning_rate': 0.001}\n",
      "-------Best params for Gradboost----------\n",
      "{'n_estimators': 100, 'min_samples_split': 4, 'min_samples_leaf': 1, 'loss': 'huber', 'learning_rate': 1}\n",
      "-------Best params for XGboost----------\n",
      "{'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model_param={}\n",
    "for name,model,params in randomcv_models:\n",
    "    random=RandomizedSearchCV(estimator=model,\n",
    "                              param_distributions=params,\n",
    "                              n_iter=100,\n",
    "                              cv=3,\n",
    "                              verbose=2,\n",
    "                              n_jobs=-1)\n",
    "    random.fit(X_train,y_train)\n",
    "    model_param[name]=random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"-------Best params for {model_name}----------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest\n",
      "Model performance for training dataset\n",
      "- Mean Absolute error:1325.7282\n",
      "- Mean Squared error:2069.3105\n",
      "-R2 score:0.9676\n",
      "-------------------------------------\n",
      "Model performance for Test Dataset\n",
      "- Mean Absolute error:2863.5418\n",
      "- Mean Squared error:3911.5617\n",
      "-R2 score:0.8216\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for training dataset\n",
      "- Mean Absolute error:2177.3974\n",
      "- Mean Squared error:3044.2334\n",
      "-R2 score:0.9299\n",
      "-------------------------------------\n",
      "Model performance for Test Dataset\n",
      "- Mean Absolute error:3423.7056\n",
      "- Mean Squared error:4670.4713\n",
      "-R2 score:0.7456\n",
      "===================================\n",
      "\n",
      "\n",
      "GradientBoost\n",
      "Model performance for training dataset\n",
      "- Mean Absolute error:88.7037\n",
      "- Mean Squared error:313.5975\n",
      "-R2 score:0.9993\n",
      "-------------------------------------\n",
      "Model performance for Test Dataset\n",
      "- Mean Absolute error:2838.0644\n",
      "- Mean Squared error:4506.5748\n",
      "-R2 score:0.7632\n",
      "===================================\n",
      "\n",
      "\n",
      "XGboost\n",
      "Model performance for training dataset\n",
      "- Mean Absolute error:614.0692\n",
      "- Mean Squared error:1016.3033\n",
      "-R2 score:0.9922\n",
      "-------------------------------------\n",
      "Model performance for Test Dataset\n",
      "- Mean Absolute error:4278.9195\n",
      "- Mean Squared error:6163.8951\n",
      "-R2 score:0.5569\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models={\n",
    "    \"Random forest\": RandomForestRegressor(n_estimators=200,min_samples_split=2,max_features=8,max_depth=None),\n",
    "    \"Adaboost\": AdaBoostRegressor(n_estimators=150,loss='linear',learning_rate=0.01),\n",
    "    \"GradientBoost\": GradientBoostingRegressor(n_estimators=150,min_samples_split=4,min_samples_leaf=1,loss='huber',learning_rate=1),\n",
    "    \"XGboost\": XGBRegressor(n_estimators=100,max_depth= 8, learning_rate= 0.1, colsample_bytree= 0.3)\n",
    "}\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "\n",
    "    y_train_pred=model.predict(X_train)\n",
    "    y_test_pred=model.predict(X_test)\n",
    "\n",
    "    model_train_mae,model_train_mse,model_train_r2=evaluate_model(y_train,y_train_pred)\n",
    "    model_test_mae,model_test_mse,model_test_r2=evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "\n",
    "    print('Model performance for training dataset')\n",
    "    print(\"- Mean Absolute error:{:.4f}\".format(model_train_mae))\n",
    "    print(\"- Mean Squared error:{:.4f}\".format(model_train_mse))\n",
    "    print(\"-R2 score:{:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"Model performance for Test Dataset\")\n",
    "    print(\"- Mean Absolute error:{:.4f}\".format(model_test_mae))\n",
    "    print(\"- Mean Squared error:{:.4f}\".format(model_test_mse))\n",
    "    print(\"-R2 score:{:.4f}\".format(model_test_r2))\n",
    "    r2_list.append(model_test_r2)\n",
    "\n",
    "    print(\"=\"*35)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.821573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.745621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGboost</td>\n",
       "      <td>0.556932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Name  R2_score\n",
       "0  Random forest  0.821573\n",
       "2  GradientBoost  0.763161\n",
       "1       Adaboost  0.745621\n",
       "3        XGboost  0.556932"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list,r2_list)),columns=['Model Name','R2_score']).sort_values(by=\"R2_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:0.8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1692211f0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf=RandomForestRegressor(n_estimators=200,min_samples_split=2,max_features=8,max_depth=None)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "score=r2_score(y_test,y_pred)\n",
    "print(\"R2 Score:{:.4f}\".format(score))\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11500</td>\n",
       "      <td>7738.100000</td>\n",
       "      <td>3761.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6580</td>\n",
       "      <td>5679.937500</td>\n",
       "      <td>900.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10450</td>\n",
       "      <td>8592.794167</td>\n",
       "      <td>1857.205833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1750</td>\n",
       "      <td>5458.837500</td>\n",
       "      <td>-3708.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>26500</td>\n",
       "      <td>18538.547500</td>\n",
       "      <td>7961.452500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6350</td>\n",
       "      <td>4782.400000</td>\n",
       "      <td>1567.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9760</td>\n",
       "      <td>14504.859405</td>\n",
       "      <td>-4744.859405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12500</td>\n",
       "      <td>10582.600000</td>\n",
       "      <td>1917.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1850</td>\n",
       "      <td>4819.175000</td>\n",
       "      <td>-2969.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1850</td>\n",
       "      <td>2256.100000</td>\n",
       "      <td>-406.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>38500</td>\n",
       "      <td>28590.910000</td>\n",
       "      <td>9909.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11500</td>\n",
       "      <td>10582.600000</td>\n",
       "      <td>917.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2950</td>\n",
       "      <td>7730.413333</td>\n",
       "      <td>-4780.413333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3850</td>\n",
       "      <td>4317.200000</td>\n",
       "      <td>-467.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2350</td>\n",
       "      <td>2347.500000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1750</td>\n",
       "      <td>4764.612500</td>\n",
       "      <td>-3014.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>8560</td>\n",
       "      <td>8592.794167</td>\n",
       "      <td>-32.794167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5530</td>\n",
       "      <td>9168.600000</td>\n",
       "      <td>-3638.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual     predicted   difference\n",
       "4    11500   7738.100000  3761.900000\n",
       "62    6580   5679.937500   900.062500\n",
       "18   10450   8592.794167  1857.205833\n",
       "0     1750   5458.837500 -3708.837500\n",
       "28   26500  18538.547500  7961.452500\n",
       "50    6350   4782.400000  1567.600000\n",
       "10    9760  14504.859405 -4744.859405\n",
       "34   12500  10582.600000  1917.400000\n",
       "12    1850   4819.175000 -2969.175000\n",
       "54    1850   2256.100000  -406.100000\n",
       "47   38500  28590.910000  9909.090000\n",
       "31   11500  10582.600000   917.400000\n",
       "9     2950   7730.413333 -4780.413333\n",
       "45    3850   4317.200000  -467.200000\n",
       "5     2350   2347.500000     2.500000\n",
       "22    1750   4764.612500 -3014.612500\n",
       "56    8560   8592.794167   -32.794167\n",
       "49    5530   9168.600000 -3638.600000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df=pd.DataFrame({\"actual\":y_test,\"predicted\":y_pred,\"difference\":y_test-y_pred})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
